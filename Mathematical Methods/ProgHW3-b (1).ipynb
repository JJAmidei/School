{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c15c0c",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Use the Jacobi Method to solve the following system for $n = 100$. Use the stopping criterion that the infinity norm of the difference between the iterate and true solution is less than $10^{-6}$ or the number of iterations reaches $n$. The correct solution is $[1,\\dots,1]$, compute the right-hand side $b$ using the np.dot function to multiply matrix and vector. Report the number of steps needed and the forward error (difference from the solution) and the backward error (the residual) in the infinity norm. The system is\n",
    "\\begin{equation*}\n",
    "\\left[\\begin{array}{rcccc}{3} & {-1} & {} & {} & {} \\\\ {-1} & {3} & {-1} & {} & {} \\\\ {} & {\\ddots} & {\\ddots} & {\\ddots} & {} \\\\ {} & {} & {-1} & {3} & {-1} \\\\ {} & {} & {} & {-1} & {3}\\end{array}\\right]\\left[\\begin{array}{c}{x_{1}} \\\\ {\\vdots} \\\\ {x_{n}}\\end{array}\\right]=b\n",
    "\\end{equation*}\n",
    "**MATH 5660 only:**\n",
    "\n",
    "(a) Same as above, but do not store the matrix $A$. This is possible since you know what its entries are and it has a special structure so you can just hardcode them and compute $b[i]$ and new $x[i]$ by formulas. $Make sure you get the same result as above.\n",
    "\n",
    "(b) Change the diagonal entries of $A$ to $2$, compute new $b$, and run your code for $n=100, 1000, 10000$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc855125",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Carry out the steps of Problem 1 with $n = 100$ for \n",
    "\n",
    "(a) Gauss–Seidel Method and\n",
    "\n",
    "(b) SOR with $\\omega = 1.2$.\n",
    "\n",
    "Which one converges faster - Jacobi, Gauss-Seidel, or SOR?\n",
    "\n",
    "**MATH 5660 only:**\n",
    "\n",
    "Carry out the steps as in Problem 1 part for MATH 5660 only, with the Gauss–Seidel Method and SOR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f770b",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Solve the system $Hx = b$ by the Conjugate Gradient Method, where $H$ is the $n \\times n$ Hilbert matrix (see Wikipedia for definition) and $b$ is the vector of all ones, for \n",
    "\n",
    "(a) $n = 4$\n",
    "\n",
    "(b) $n = 8$.\n",
    "\n",
    "What can you say about the solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c3d41",
   "metadata": {},
   "source": [
    "**MATH 5660 only:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4dcb4",
   "metadata": {},
   "source": [
    "Convergence of iterative methods like the Conjugate Gradient Method can be accelerated\n",
    "by the use of a technique called **preconditioning**. The convergence rates of iterative\n",
    "methods often depend, directly or indirectly, on the condition number of the\n",
    "coefficient matrix A. The idea of preconditioning is to reduce the effective condition\n",
    "number of the problem.\n",
    "\n",
    "The preconditioned form of the $n \\times n$ linear system $A\\boldsymbol{x} = \\boldsymbol{b}$ is\n",
    "$$\n",
    "M^{-1}A\\boldsymbol{x} = M^{-1}\\boldsymbol{b},\n",
    "$$\n",
    "where $M$ is an invertible $n \\times n$ matrix called the **preconditioner**.\n",
    "\n",
    "When $A$ is a symmetric positive-definite $n \\times n$ matrix, we will choose a symmetric\n",
    "positive-definite matrix $M$ for use as a preconditioner. A particularly simple choice is the **Jacobi preconditioner** $M = D$, where $D$ is the diagonal of $A$. The Preconditioned Conjugate Gradient\n",
    "Method is now easy to describe: Replace $A\\boldsymbol{x} = \\boldsymbol{b}$ with the preconditioned equation $M^{−1} A\\boldsymbol{x} = M^{−1}\\boldsymbol{b}$, and replace the Euclidean inner product with $(\\boldsymbol{v},\\boldsymbol{w})M$.\n",
    "\n",
    "To convert Algorithm 2 in Section 3.3 to the preconditioned version, let $\\boldsymbol{z}_k = M^{-1}\\boldsymbol{b} - M^{-1}A\\boldsymbol{x}_k = M^{-1}\\boldsymbol{r}_k$. Then the algorithm is\n",
    "\n",
    "1. Initialize $\\boldsymbol{x}_0$ as any vector. Set $\\boldsymbol{r}_0=\\boldsymbol{b}-A\\boldsymbol{x}_0$ and $\\boldsymbol{u}_0=\\boldsymbol{z}_0=M^{-1}\\boldsymbol{r}_0$.\n",
    "\n",
    "2. For $k=0, 1, \\dots, n-1$:\n",
    "\n",
    "    1. $a_k=\\frac{\\boldsymbol{r}_k^T \\boldsymbol{z}_k}{\\boldsymbol{u}_k^TA\\boldsymbol{u}_k}$\n",
    "    2. $\\boldsymbol{x}_{k+1} = \\boldsymbol{x}_k + a_k \\boldsymbol{u}_k$\n",
    "    3. $\\boldsymbol{r}_{k+1} = \\boldsymbol{r}_{k}-a_kA\\boldsymbol{u}_{k}$\n",
    "    4. if ($||\\boldsymbol{r}_{k+1}|| < \\epsilon$):\n",
    "        1. break\n",
    "    5. $\\boldsymbol{z}_{k+1} = M^{-1}\\boldsymbol{r}_{k+1}$\n",
    "    6. $\\boldsymbol{b}_k = \\frac{\\boldsymbol{r}_{k+1}^T\\boldsymbol{z}_{k+1}}{\\boldsymbol{r}_{k}^T\\boldsymbol{z}_{k}}$\n",
    "    7. $\\boldsymbol{u}_{k+1} = \\boldsymbol{z}_{k+1} + \\boldsymbol{b}_k\\boldsymbol{u}_{k}$\n",
    "\n",
    "3. return $\\boldsymbol{x}_{k+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926388d1",
   "metadata": {},
   "source": [
    "Now, consider the following problem.\n",
    "\n",
    "Let $A$ be the $n \\times n$ matrix with $n = 1000$ and entries $A(i, i) = i$, $A(i, i+1) = A(i+1, i) = 1/2$, $A(i, i + 2) = A(i + 2, i ) = 1/2$ for all $i$ that fit\n",
    "within the matrix. \n",
    "\n",
    "(a) Take a look at the nonzero structure of the matrix using plt.spy(A). \n",
    "\n",
    "(b) Let $\\boldsymbol{x}_e$ be the vector of $n$ ones (exact solution). Set $\\boldsymbol{b} = A\\boldsymbol{x}_e$, and apply the Conjugate Gradient Method, without preconditioner, and\n",
    "with the Jacobi preconditioner. Compare errors (using 2-norm) of the two runs in a plot versus step number (using semilogy). (So you need to modify the conjugate gradient codes to keep track of and return the solutions of all steps.) Use eps = 1e-10. \n",
    "\n",
    "The two methods may converge in different number of steps. Which one do you see is faster?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
