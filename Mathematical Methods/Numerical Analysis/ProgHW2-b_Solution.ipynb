{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from base64 import b64decode\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Apply Fixed-Point Iteration to find the solution of the equation \n",
    "\n",
    "$$e^x+x=7$$\n",
    "\n",
    "Iterate until the absolute difference of two successive iterates is less than $\\epsilon=10^{-8}$.\n",
    "\n",
    "(Hint: make sure you use a function $g(x)$ that theoretically works; otherwise the algorithm may diverge; the initial guess can be obtained from a plot of the function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for fixed-point iteration \n",
    "# The stopping criterion is iterates from two successive steps are close under some tolerance\n",
    "# if f(x)=0 can be written as g(x)=x\n",
    "\n",
    "def fpi_tol(g, x_0, tol):\n",
    "    \"\"\"\n",
    "    g: the function g(x) in g(x)=x\n",
    "    x_0: the initial guess\n",
    "    k: the tolerance. The algorithm stops if two successive iterates have a difference\n",
    "       less than the tol\n",
    "    \"\"\"\n",
    "    nstep = 0\n",
    "    x = g(x_0)\n",
    "    while (np.abs(x-x_0) > tol):\n",
    "        x_0 = x\n",
    "        x = g(x_0)\n",
    "        nstep += 1\n",
    "    \n",
    "    return x, nstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check the plot of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGxCAYAAACju/aQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8iUlEQVR4nO3deXhU5cH+8XuyTUKWCdl3wk5YZZPFjYiiuCCuoK+KVm1d31p+1Lq8rWKrtLW2b6uty1uL2mrR1ooLbiiICyJrILKHLSELIdtMyDLZzu+PLBISMGCSc2bm+7muuXTOnCQ3IzC3z/Oc59gMwzAEAABgUX5mBwAAADgRygoAALA0ygoAALA0ygoAALA0ygoAALA0ygoAALA0ygoAALA0ygoAALA0ygoAALA0ygrgw1588UXZbLa2R0BAgFJSUnTzzTcrPz+/W3+WzWbT3Xff/Z3nffrpp7LZbPr000+79ed/H3/60580efJkxcTEyG63Ky0tTXPnztXWrVvNjgb4hACzAwAw3+LFizVs2DDV1NTos88+06JFi7Rq1SplZ2crNDTU7HimKy0t1cyZMzVmzBj17dtXe/fu1a9//WtNmjRJGzZs0NChQ82OCHg1ygoAjRw5UhMmTJAkZWZmqrGxUb/85S+1dOlS/dd//VenX1NdXa0+ffr0ZkzTLFy4sN3zc845R5MnT9bw4cP1yiuv6NFHHzUpGeAbmAYC0MHkyZMlSQcOHJAk3XTTTQoLC1N2drZmzJih8PBwTZ8+XZJUVlamO++8U8nJyQoKCtKAAQP00EMPye12d/q9n3vuOQ0ZMkR2u13Dhw/XkiVLupRp/fr1mjVrlqKiohQcHKyxY8fq9ddfb3dO67TWihUrdNtttyk6OloRERG68cYbVVVVpaKiIl1zzTWKjIxUYmKiFixYoPr6+lN6j2JjYyVJAQH8Px/Q0/hTBqCDnJwcSd9+IEtSXV2dZs2apR/96Ee6//771dDQoNraWmVmZmrPnj1auHChRo8erc8//1yLFi1SVlaWli1b1u77vv3221q5cqUeffRRhYaG6i9/+YuuvfZaBQQE6KqrrjpunpUrV+rCCy/UpEmT9Oyzz8rhcGjJkiWaM2eOqqurddNNN7U7/9Zbb9UVV1yhJUuWaNOmTXrwwQfV0NCgnTt36oorrtAPf/hDffzxx/rNb36jpKQkzZ8/v0vvS2NjoxoaGrRv3z7df//9iouL080339zFdxXAKTMA+KzFixcbkow1a9YY9fX1RmVlpfHuu+8asbGxRnh4uFFUVGQYhmHMmzfPkGT87W9/a/f1zz77rCHJeP3119sd/81vfmNIMj766KO2Y5KMkJCQtu9pGIbR0NBgDBs2zBg0aFDbsZUrVxqSjJUrV7YdGzZsmDF27Fijvr6+3c+55JJLjMTERKOxsbHdr+eee+5pd97s2bMNScbvf//7dsdPO+00Y9y4cV19uwy73W5IMiQZQ4YMMbZt29blrwVw6pgGAqDJkycrMDBQ4eHhuuSSS5SQkKD3339f8fHx7c678sor2z1fsWKFQkNDO4yKtI50fPLJJ+2OT58+vd339Pf315w5c5STk6ODBw92mi0nJ0c7duxoWzvT0NDQ9rjoootUWFionTt3tvuaSy65pN3zjIwMSdLFF1/c4XjrVFdXrF69Wl999ZX+8Y9/KDw8XJmZmVwRBPQCpoEA6OWXX1ZGRoYCAgIUHx+vxMTEDuf06dNHERER7Y6VlpYqISFBNput3fG4uDgFBASotLS03fGEhIQO37f1WGlpqVJSUjq8fujQIUnSggULtGDBgk7zl5SUtHseFRXV7nlQUNBxj9fW1nb6PTszbtw4Sc3lbtasWRo0aJAefPBBvfXWW13+HgBOHmUFgDIyMtquBjqeYwuJJEVHR+vrr7+WYRjtXi8uLlZDQ4NiYmLanV9UVNThe7Qei46O7vTntn6PBx54QFdccUWn55hx6XB4eLiGDRumXbt29frPBnwNZQXAKZs+fbpef/11LV26VJdffnnb8Zdffrnt9aN98sknOnToUNtUUGNjo1577TUNHDiw01EVqbmIDB48WJs3b9bjjz/eQ7+Sk1dSUqLs7GydccYZZkcBvB5lBcApu/HGG/XnP/9Z8+bN0/79+zVq1Ch98cUXevzxx3XRRRfpvPPOa3d+TEyMzj33XP385z9vuxpox44d33n58nPPPaeZM2fqggsu0E033aTk5GSVlZVp+/bt2rhxo/71r3/12K/R6XTq/PPP13XXXafBgwcrJCREu3bt0h//+Ee53W49/PDDPfazATSjrAA4ZcHBwVq5cqUeeughPfHEEzp8+LCSk5O1YMGCTj/EZ82apREjRuh//ud/lJubq4EDB+qVV17RnDlzTvhzMjMztXbtWj322GO69957VV5erujoaA0fPlzXXHNNT/3yJDX/GseMGaPnn39eeXl5qq2tVUJCgqZNm6Y33nhDw4cP79GfD0CyGYZhmB0CAADgeLh0GQAAWBplBQAAWBplBQAAWBplBQAAWBplBQAAWBplBQAAWJrH77PS1NSkgoIChYeHd7odOAAAsB7DMFRZWamkpCT5+Z147MTjy0pBQYFSU1PNjgEAAE5BXl7ecW+30crjy0p4eLik5l/ssXeEBQAA1uRyuZSamtr2OX4iHl9WWqd+IiIiKCsAAHiYrizhYIEtAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAACwNMoKAADo1IYDZVrwr836ZPshU3N4/F2XAQBAz/ho6yH9e8NBNRmGpmfEm5aDkRUAANCpVbsOS5LOGRJrag7KCgAA6OCQq1Y7iipls0lnDaasAAAAi/msZVRldLJDUaFBpmahrAAAgA4+210iSTrb5CkgibICAACO0dhk6PPdzSMrlBUAAGA5WXkVqqiuV0RwgMamRpodh7ICAADa+3RnsaTmUZUAf/OrgvkJAACApaxsKSuZQ+NMTtKMsgIAANoUV9bqm3yXJOmcoeavV5EoKwAA4CirdrZcspziUEyY3eQ0zXq0rHz22We69NJLlZSUJJvNpqVLl7Z7/aabbpLNZmv3mDx5ck9GAgAAJ/BpS1mZZpEpIKmHy0pVVZXGjBmjp59++rjnXHjhhSosLGx7vPfeez0ZCQAAHEd9Y5M+a7lkOdMiU0BSD9/IcObMmZo5c+YJz7Hb7UpISOjy93S73XK73W3PXS7XKecDAADf2nigXJW1DYoKDdLolEiz47Qxfc3Kp59+qri4OA0ZMkS33XabiouLT3j+okWL5HA42h6pqam9lBQAAO+2cue3Ny7097OZnOZbppaVmTNn6pVXXtGKFSv05JNPat26dTr33HPbjZwc64EHHpDT6Wx75OXl9WJiAAC8V+v+KtMsNAUk9fA00HeZM2dO27+PHDlSEyZMUL9+/bRs2TJdccUVnX6N3W6X3W6N1ckAAHiLQmdN212Wzzb5LsvHMn0a6GiJiYnq16+fdu/ebXYUAAB8SutVQGNTI9XX5LssH8tSZaW0tFR5eXlKTEw0OwoAAD5l5Q5r7Vp7tB6dBjpy5IhycnLanu/bt09ZWVmKiopSVFSUHnnkEV155ZVKTEzU/v379eCDDyomJkaXX355T8YCAABHcTc06sucEknW2l+lVY+WlfXr1yszM7Pt+fz58yVJ8+bN0zPPPKPs7Gy9/PLLqqioUGJiojIzM/Xaa68pPDy8J2MBAICjfLWnVFV1jYqPsGtkcoTZcTro0bIybdo0GYZx3Nc//PDDnvzxAACgCz7Z3jwFND0jXjabdS5ZbmWpNSsAAKB3GYahj7cfkiSdnxFvcprOUVYAAPBhWwtcKnTWKiTQX1MGRpsdp1OUFQAAfFjrFNBZg2MUHOhvcprOUVYAAPBhrVNA5w235hSQRFkBAMBnFTlrlZ3vlM0mnTvMepcst6KsAADgoz7Z0TyqMjY1UjFh1r2VDWUFAAAf9fE2608BSZQVAAB8UnVdg77cUypJOs+ilyy3oqwAAOCDPt9dorqGJqVF9dHguDCz45wQZQUAAB/UNgVk0V1rj0ZZAQDAxzQ2GVrRcpfl8zKsexVQK8oKAAA+ZsOBcpVW1ckREqiJ/aPMjvOdKCsAAPiYD74pkiRNz4hToL/1q4D1EwIAgG5jGIY+3NpcVi4ckWBymq6hrAAA4EO+yXcpv6JGIYH+OntIrNlxuoSyAgCAD2kdVckcFmvZGxcei7ICAIAP+aClrFzgIVNAEmUFAACfkVNcqZziIwr0tynTwjcuPBZlBQAAH/Hh1uaN4M4YFKOI4ECT03QdZQUAAB/ResmyJ00BSZQVAAB8Qn5FjbLznbLZpPMtfpflY1FWAADwAR+2jKpMTI9STJjd5DQnh7ICAIAP+MDDNoI7GmUFAAAvd7jSrfX7yyRJM0Z41hSQRFkBAMDrffBNoZoMaUxqpFL69jE7zkmjrAAA4OXe3VIoSbpkVKLJSU4NZQUAAC92yFWrtS1TQBeNpqwAAACLeT+7UIYhjUuLVHJkiNlxTgllBQAAL7Ysu3kK6OLRSSYnOXWUFQAAvFShs0br9pdLki4a5XmXLLeirAAA4KXey27dCK6vEh2eOQUkUVYAAPBay7YUSJIu9tCrgFpRVgAA8EL5FTXamFshm02aSVkBAABW817L3ioT06MUHxFscprvh7ICAIAXerflKqBLPXRvlaNRVgAA8DJ5ZdXanFchP5t0wUjPvQqoFWUFAAAv07q3yqT+0YoL9+wpIImyAgCA11m6KV+SdMkYz58CkigrAAB4lZ1FldpRVKlAf5vHX7LcirICAIAXWZrVPKoybWicIvsEmZyme1BWAADwEk1Nht7Oat4IbvZpySan6T6UFQAAvMS6/WXKr6hRuD1A0zPizI7TbSgrAAB4iaUtoyoXjkxQcKC/yWm6D2UFAAAv4G5o1HstlyzPHus9U0ASZQUAAK/w6c7DctbUKy7crskDos2O060oKwAAeIG3Wq4Cuuy0JPn72UxO070oKwAAeDhXbb0+3l4sSbrMi64CakVZAQDAw32QXaS6hiYNigvTiKQIs+N0O8oKAAAernUjuMvHJstm864pIImyAgCARyt01uirvaWSpFljkkxO0zMoKwAAeLD/bMyXYUin949SalQfs+P0CMoKAAAeyjAM/XvDQUnS1eNTTE7TcygrAAB4qA0HyrWvpEp9gvx1kZfcYbkzPVpWPvvsM1166aVKSkqSzWbT0qVL271uGIYeeeQRJSUlKSQkRNOmTdPWrVt7MhIAAF6jdVTlolGJCrUHmJym5/RoWamqqtKYMWP09NNPd/r6b3/7W/3+97/X008/rXXr1ikhIUHnn3++KisrezIWAAAer7quQe9uad5e/yovngKSpB6tYTNnztTMmTM7fc0wDP3v//6vHnroIV1xxRWSpJdeeknx8fF69dVX9aMf/agnowEA4NE+3FqkI+4GpUX10enpUWbH6VGmrVnZt2+fioqKNGPGjLZjdrtd55xzjlavXn3cr3O73XK5XO0eAAD4mn+tb54CunJcivy8bHv9Y5lWVoqKiiRJ8fHx7Y7Hx8e3vdaZRYsWyeFwtD1SU1N7NCcAAFZzsLxaq/c0761y5Xjv217/WKZfDXTsTnuGYZxw970HHnhATqez7ZGXl9fTEQEAsJQ3NjTvWDt1YLRS+nrn3ipHM23pcEJCgqTmEZbExG8vtyouLu4w2nI0u90uu93e4/kAALCipiZD/97Y/D/qV0/w7oW1rUwbWenfv78SEhK0fPnytmN1dXVatWqVpk6dalYsAAAsbe3+MuWV1SjMHqALR3jv3ipH69GRlSNHjignJ6ft+b59+5SVlaWoqCilpaXp3nvv1eOPP67Bgwdr8ODBevzxx9WnTx9dd911PRkLAACP9fr65lGVS0YnKiTI3+Q0vaNHy8r69euVmZnZ9nz+/PmSpHnz5unFF1/Ufffdp5qaGt15550qLy/XpEmT9NFHHyk8PLwnYwEA4JGc1fVa1rK3ypyJvnOBic0wDMPsEN+Hy+WSw+GQ0+lURESE2XEAAOgxL365T4+8s03DEsL1/o/POuEFKVZ3Mp/fpl8NBAAAvpthGPrn2uYpoOsmpXl0UTlZlBUAADzAxtxy7TxUqeBAP112mvfvrXI0ygoAAB7g1a9bF9YmyRESaHKa3kVZAQDA4pzV9Xp3S4Ek6drT00xO0/soKwAAWNzSrHy5G5o0ND5c49IizY7T6ygrAABYWPPC2lxJvrewthVlBQAAC9uYW6EdRZWyB/hp9ljfWljbirICAICFtY6q+OLC2laUFQAALMpZ8+3C2usm+c6OtceirAAAYFH/Wp+n2vrWhbV9zY5jGsoKAAAW1NRk6O9rDkiSbpzazycX1rairAAAYEGrdh/WgdJqhQcH6HIfXVjbirICAIAFvbx6vyTpmgmp6hMUYG4Yk1FWAACwmP0lVfp012FJ0g2T+5mcxnyUFQAALOYfaw7IMKRpQ2OVHhNqdhzTUVYAALCQ6roGvb6++aaF86akmxvGIigrAABYyFtZBXLVNigtqo/OGRJrdhxLoKwAAGARhmHopZaFtTdO6Sc/P9+9XPlolBUAACxi3f5y7SiqVHCgn64e77s71h6LsgIAgEW8uHqfJGn2acly9PHN+wB1hrICAIAF5JVV64NviiRJN5/R3+Q01kJZAQDAAhZ/uV9NhnTW4BgNTQg3O46lUFYAADCZq7Zer63LlSTddtYAk9NYD2UFAACTvbY2T1V1jRoSH6azBseYHcdyKCsAAJiovrFJi79sXlh765kDfPruysdDWQEAwETvf1OkAmetYsKCNOu0JLPjWBJlBQAAkxiGob9+vleSdMPkdAUH+pucyJooKwAAmGT9gXJtOeiUPcBP109OMzuOZVFWAAAwSeuoyhXjUhQdZjc5jXVRVgAAMMG+kip9tO2QJOmWM9PNDWNxlBUAAEzw3Ko9Mgxp+rA4DYpjE7gToawAANDLipy1emPjQUnSnZkDTU5jfZQVAAB62Qtf7FV9o6HT+0dpfL8os+NYHmUFAIBeVFFdp1e+bt5a/45pjKp0BWUFAIBe9NLqA6qua9TwxAhNGxJrdhyPQFkBAKCXVNc16MXVzVvr3zFtIFvrdxFlBQCAXvLPtXkqr65Xv+g+mjkywew4HoOyAgBAL6hraGrbBO5HZw9UgD8fwV3FOwUAQC9YmpWvQmet4sLtunJ8stlxPAplBQCAHtbQ2KS/rMyRJN1yZn/ZA7hh4cmgrAAA0MPeyirQ/tJqRYUG6frJ/cyO43EoKwAA9KCGxiY93TKqcttZAxRqDzA5keehrAAA0IPe3lygfSVV6tsnUDdOYVTlVFBWAADoIY1Nhp5e0TKqcjajKqeKsgIAQA95Z3OB9pZUKbJPoG6ckm52HI9FWQEAoAc0Nhn604rdkprXqoQxqnLKKCsAAPSAd7cUaO/h5lGVeVPTzY7j0SgrAAB0s8YmQ3/6hFGV7kJZAQCgmy3dlK89h6vkCOEKoO5AWQEAoBvVNTTpDx/vktR8Z+Xw4ECTE3k+ygoAAN1oybpcHSyvUVy4XfO4AqhbUFYAAOgm1XUN+tMnzfuq3DN9sEKCuAdQd6CsAADQTRZ/uV8lR9xKi+qjORNSzY7jNSgrAAB0A2d1vZ5btUeS9JPzBysogI/Y7mL6O/nII4/IZrO1eyQkJJgdCwCAk/LcZ3vkqm3Q0PhwzRqTbHYcr2KJC79HjBihjz/+uO25vz9zfAAAz1FcWavFX+6XJC24YKj8/WzmBvIyligrAQEBjKYAADzWU5/kqKa+UWPTInVeRpzZcbyO6dNAkrR7924lJSWpf//+mjt3rvbu3Xvcc91ut1wuV7sHAABm2XP4iF5dmytJuu+CYbLZGFXpbqaXlUmTJunll1/Whx9+qP/7v/9TUVGRpk6dqtLS0k7PX7RokRwOR9sjNZXV1gAA8yx6b4camwydlxGnKQOjzY7jlWyGYRhmhzhaVVWVBg4cqPvuu0/z58/v8Lrb7Zbb7W577nK5lJqaKqfTqYiIiN6MCgDwcV/tKdW1/7dG/n42fXjvWRoUF252JI/hcrnkcDi69PltiTUrRwsNDdWoUaO0e/fuTl+32+2y2+29nAoAgPaamgw9/t52SdK1p6dSVHqQ6dNAx3K73dq+fbsSExPNjgIAwHG9vblA2flOhdkDdO95Q8yO49VMLysLFizQqlWrtG/fPn399de66qqr5HK5NG/ePLOjAQDQqdr6Rv32gx2Smm9WGBPGiH9PMn0a6ODBg7r22mtVUlKi2NhYTZ48WWvWrFG/ftxSGwBgTX/7cp8KnLVKdATrljP7mx3H65leVpYsWWJ2BAAAuqzkiFt/Wdm8rf5PLxiq4EA2Mu1ppk8DAQDgSZ74YKeOuBs0MjlCs09jW/3eQFkBAKCLNudV6PUNeZKkRy4dIT+21e8VlBUAALqgqcnQI+9slWFIl49N1oT0KLMj+QzKCgAAXfCfTfnalFuh0CB/3T9zmNlxfAplBQCA71BZW69fv998qfI90wcrPiLY5ES+hbICAMB3eGpFjkqOuNU/JlQ3n5FudhyfQ1kBAOAEcoqP6G9f7JMk/eKS4bIHcKlyb6OsAABwHIZhaOE7W9XQZOjcYXHKHBZndiSfRFkBAOA43tlSqM93lygowE+/uGS42XF8FmUFAIBOOGvq9ct3t0mS7s4cpPSYUJMT+S7KCgAAnfjdhzt1uNKtAbGh+tE5A8yO49MoKwAAHCMrr0L/+PqAJOlXs0eyqNZklBUAAI7S0Nikh97MlmFIV4xN1tSBMWZH8nmUFQAAjvLSVwe0tcAlR0igHrw4w+w4EGUFAIA2BRU1+v1HOyVJ988cppgwu8mJIFFWAACQ1LynyoNvZquqrlHj+/XVnAmpZkdCC8oKAACS3tyUr093HlZQgJ9+c+Vo+fnZzI6EFpQVAIDPK66s1cJ3mvdU+fH0wRoUF2ZyIhyNsgIA8HkPv7VVzpp6jUiK0A/PZk8Vq6GsAAB82vvZhXr/myIF+Nn026tGK9Cfj0ar4b8IAMBnVVTX6edvbZUk3X7OQI1IcpicCJ2hrAAAfNbCd7ap5Ihbg+LCdM/0QWbHwXFQVgAAPun97EK9uSlffjbpt1eNZkt9C6OsAAB8TrGrVg++mS1JumPaQI1L62tyIpwIZQUA4FMMw9DP3tii8urmq39+PH2I2ZHwHSgrAACfsmRdnla2bP72hzmnKSiAj0Kr478QAMBnHCit0i/fbd787aczhmpIfLjJidAVlBUAgE9obDL0/17frOq6Rk3qH6VbzuxvdiR0EWUFAOATnl21R+sPlCvMHqDfXT2Ge/94EMoKAMDrbcwt1++X75Ik/eLS4UqN6mNyIpwMygoAwKs5a+r13//cpMYmQ5eMTtTV41PMjoSTRFkBAHgtwzD04H+ydbC8RqlRIXr8ilGy2Zj+8TSUFQCA11qyLk/LsgsV4GfTn+aOVURwoNmRcAooKwAAr7TrUKUWvtN8k8IFFwzVWHap9ViUFQCA16mtb9Tdr25UbX2Tzhocox+eNcDsSPgeKCsAAK+z8J2t2nXoiGLC7Pr9NadxmbKHo6wAALzKv9bn6Z9r82SzSb+/Zoxiw+1mR8L3RFkBAHiNrQVO/c/SbyRJ904forOHxJqcCN2BsgIA8ArOmnrd8Y+Ncjc0adrQWN1z7iCzI6GbUFYAAB6vqcnQ/3s9S7ll1UqODNH/zmGdijehrAAAPN6zn+3Rx9uLFRTgp2evH6/IPkFmR0I3oqwAADzalzkl+t2HOyVJj84aoVEpDpMTobtRVgAAHiu3tFp3vbpRTYZ09fgUzZmYanYk9ADKCgDAI1XW1uvWl9eporpeY1Ij9cvZI7nvj5eirAAAPE5Tk6GfvJalXYeOKC7crudvGK/gQH+zY6GHUFYAAB7nyeU72xbUPn/jBMVHBJsdCT2IsgIA8ChvZeXrzyv3SJJ+c+UonZYaaW4g9DjKCgDAY2QfdOq+f2+RJP3onAG6fGyKyYnQGygrAACPcLC8Wj94aZ3cDU3KHBqr+y4YZnYk9BLKCgDA8pw19frBi+t0uNKtYQnh+tO1Y+XPDrU+g7ICALC0uoYm3fGPDdp16IjiI+z6200TFR4caHYs9CLKCgDAsgzD0AP/ydbqPaUKDfLX326aqKTIELNjoZdRVgAAlvWnT3L0xsaD8vez6en/GqcRSWyl74ssUVb+8pe/qH///goODtb48eP1+eefmx0JAGCyf284qD98vEuS9MvLRipzaJzJiWAW08vKa6+9pnvvvVcPPfSQNm3apLPOOkszZ85Ubm6u2dEAACb5eNsh/eyN5kuUbz9noK6blGZyIpjJZhiGYWaASZMmady4cXrmmWfajmVkZGj27NlatGjRd369y+WSw+GQs6BAERERPRkVANAL1u8v060vrZe7oUmzT0vW41dwzx9v5HK55EhKktPp/M7P74BeytSpuro6bdiwQffff3+74zNmzNDq1as7/Rq32y2329323OVyNf9LUlKP5QQA9J4JkrKOPjDPnBywDlOngUpKStTY2Kj4+Ph2x+Pj41VUVNTp1yxatEgOh6PtkZrK7cABAPBmpo6stDp2eM8wjOMO+T3wwAOaP39+23OXy9VcWAoKJKaBAMAjFVfW6oYXvlZuaY2GJoTrpR+cLkcIe6l4NZery7MippaVmJgY+fv7dxhFKS4u7jDa0sput8tut3d8ITS0+QEA8CilR9z6r1e/0e5KQ2kJUXr+jilyhHMXZa/X2NjlU02dBgoKCtL48eO1fPnydseXL1+uqVOnmpQKANBbKqrrdP0La7W7+IgSIoL1j1smKY6igmOYPg00f/583XDDDZowYYKmTJmi559/Xrm5ubr99tvNjgYA6EHOmnrd8MJabS90KTbcrldvm6S06D5mx4IFmV5W5syZo9LSUj366KMqLCzUyJEj9d5776lfv35mRwMA9JDK2nrdtHitsvOdig4N0qu3TtKA2DCzY8GiTN9n5ftq22elC9dpAwDMV+Vu0E2L12rd/nJF9gnUP2+brIxE/v72NSfz+W36DrYAAN9R5W7QLS+t07r95QoPDtA/bplEUcF3Mn0aCADgG1y19frB4nVaf6BcYfYAvfyD0zUymRsT4rtRVgAAPc5ZXa8b//a1Nh90KiI4QC/fMkmnpUaaHQsegrICAOhRZVV1uv6vX2tboUt9+wTq77dMYkQFJ4WyAgDoMcWVtbr+r19r16EjigkL0iu3TtbQhHCzY8HDUFYAAD2ioKJG1//1a+0tqVJ8hF2v3DpZg+K4PBknj7ICAOh2OcWVuuGFtSp01io5MkSv3jZJ/aK5JQpODWUFANCtNuWW6+YX16miul4DYkP191smKTkyxOxY8GCUFQBAt1m167Bu//sG1dQ3akxqpBbfNFFRoUFmx4KHo6wAALrFW1n5+n+vb1ZDk6GzBsfo2evHK9TOxwy+P34XAQC+txe+2KdfvrtNkjRrTJJ+d/UYBQWwSTq6B2UFAHDKGhqb9Mt3t+mlrw5Ikm6amq5fXDJcfn42k5PBm1BWAACnpMrdoHv+uUkrdhTLZpPuv3CYfnj2ANlsFBV0L8oKAOCkFTlr9YMX12lboUv2AD/975zTNHNUotmx4KUoKwCAk7KtwKUfvLhORa5axYQF6f9unKCxaX3NjgUvRlkBAHTZJ9sP6b//uUlVdY0aFBemxTdNVGpUH7NjwctRVgAA38kwDP15ZY6eXL5LhiFNHRitZ64fL0dIoNnR4AMoKwCAE6pyN+in/96s97KLJEk3TO6nn18ynEuT0WsoKwCA48otrdYP/75eO4oqFehv0y8vG6m5p6eZHQs+hrICAOjUF7tLdPc/N6qiul6x4XY9e/04je8XZXYs+CDKCgCgnaYmQ89/vle//WCHmgxpTGqknrt+vBIcwWZHg4+irAAA2lRU12nBvzbr4+3FkqSrxqfoV7NHKjjQ3+Rk8GWUFQCAJGlzXoXufGWj8itqFBTgp4WzRmjuxFR2pIXpKCsA4OMMw9DLXx3Qr5ZtU32joX7RffTn68ZpZLLD7GiAJMoKAPg0V229HvhPtpZtKZQkXTgiQb+9erQigtk/BdZBWQEAH7XhQJl+vCRLB8trFOBn04MXZejmM9KZ9oHlUFYAwMc0NDbpqRU5emrFbjUZUmpUiP44d6zGcX8fWBRlBQB8SF5Zte59LUsbDpRLkq4Ym6yFl41QONM+sDDKCgD4iKWb8vXzpd+o0t2gcHuAfnX5SF12WrLZsYDvRFkBAC9XVlWnX7z1jd5tWUQ7oV9f/WHOadwtGR6DsgIAXuzDrUV66M1slRypk7+fTf997mDdlTlQAf7chBCeg7ICAF6oorpOj7y9VUuzCiRJg+PC9OQ1YzQ6JdLcYMApoKwAgJf5eNshPfBmtg5XuuVnk24/Z6B+fN5g2QPYMh+eibICAF6irKpOv3p3m/6zKV+SNDA2VE9ec5pOS400NxjwPVFWAMDDGYahNzbm67Fl21ReXS8/m3Tb2QP0k/OGcANCeAXKCgB4sH0lVXrozWyt3lMqSRqWEK5FV4zSWDZ4gxehrACAB6praNJzq/boqZU5qmtoUnCgn+49b4huObO/ArnSB16GsgIAHmbtvjI99Ga2dhcfkSSdPSRWv7pspNKi2TcF3omyAgAeoshZq8ff2663NzdfjhwTFqSfXzJcs8YkcfNBeDXKCgBYnLuhUS98sU9Pr8hRdV2jbDbp2tPTdN8FQxXZJ8jseECPo6wAgIWt3FGsR9/dpn0lVZKk8f36auGsERqZ7DA5GdB7KCsAYEF7Dx/RY8u265MdxZKk2HC7Hpg5TJePTWbKBz6HsgIAFlJ6xK0/fbJbr3ydq4YmQwF+Nv3gzP6659xBCg8ONDseYArKCgBYQG19o/725T49s3KPKt0NkqRzh8XpwYsyNCguzOR0gLkoKwBgoqYmQ29uyteTH+1UgbNWkjQiKUIPXZShqYNiTE4HWANlBQBMYBiGvsgp0a/f36GtBS5JUnJkiBZcMESXjUmWnx/rUoBWlBUA6GXr9pfpiQ93au2+MklSuD1Ad2YO0s1npHMvH6ATlBUA6CWb8yr05PJd+mzXYUlSUICfrp/UT3efO0hRoeyXAhwPZQUAetiOIpee/GiXlm87JEkK8LPpmompuufcQUp0hJicDrA+ygoA9JAdRS49vSJHy7ILZRiSn02aPTZZ904fwn18gJNAWQGAbpZ90KmnVuzWRy0jKZJ08ahE/eT8wRoUF25iMsAzUVYAoJtsOFCmp1bk6NOdzWtSbDbpopGJuitzkIYnRZicDvBclBUA+B4Mw9BXe0r11IocfbW3VJLk72fTZWOSdGfmQEZSgG5AWQGAU9DQ2KQPtx7S85/v1ea8CklSoL9NV45L0R3TBqpfdKi5AQEvYmpZSU9P14EDB9od+9nPfqZf//rXJiUCgBOrrmvQ6+vy9MKX+5RXViOp+RLkuRNT9aNzBio5kqt7gO5m+sjKo48+qttuu63teVgY98AAYD3FlbV6efUB/X3NATlr6iVJffsE6oYp6bpxSj/FhNlNTgh4L9PLSnh4uBISEsyOAQCd2nWoUi98vk9vbspXXWOTJCk9uo9uOWuArhqXopAgdpwFeprNMAzDrB+enp4ut9uturo6paam6uqrr9ZPf/pTBQUdfydHt9stt9vd9tzlcik1NVVOp1MREay2B/D9NTQ26ePtxXpp9f62RbOSNC4tUj88e6DOHx4vf+7dA3wvLpdLDoejS5/fpo6s/PjHP9a4cePUt29frV27Vg888ID27dunv/71r8f9mkWLFmnhwoW9mBKAryirqtOSdbl6ZU2u8iua16P4+9l0fka8bju7v8b3izI5IeCbun1k5ZFHHvnOMrFu3TpNmDChw/E33nhDV111lUpKShQdHd3p1zKyAqC7ZR906sXV+/XOlgLVNTRP9USFBmnuxFRdP7mfklg0C3Q7U0dW7r77bs2dO/eE56Snp3d6fPLkyZKknJyc45YVu90uu52FbAC+n5q6Rr27pUCvrs3VptyKtuOjkh2aNzVdl4xO5A7IgEV0e1mJiYlRTEzMKX3tpk2bJEmJiYndGQkA2mwtcGrJ2jwtzcpXZW2DpOb9US4alah5U9M1NjVSNhvrUQArMW3NyldffaU1a9YoMzNTDodD69at009+8hPNmjVLaWlpZsUC4IWOuBv0zuYCLVmbq80HnW3HU6NCNHdimq6ekKK48GATEwI4EdPKit1u12uvvaaFCxfK7XarX79+uu2223TfffeZFQmAFzEMQ1sOOrVkXa7ezipQVV2jpOZRlBnDE3Tt6WmaOjBaflzVA1ieaWVl3LhxWrNmjVk/HoCXOuSq1Zub8vWfjQe169CRtuP9Y0I1d2KqrhyfwgZugIcxfVM4APi+ausb9eHWIr2xMV9f7D6sppZrHIMC/HThiOZRlMkDoliLAngoygoAj2QYhtbtL9d/Nh7Usi2FqnQ3tL02vl9fXTkuRRePTpQjJNDElAC6A2UFgEfJKT6itzcXaOmmfOWWVbcdT44M0ZXjknXFuBSlx3DHY8CbUFYAWF5eWbXe3VKotzcXaHuhq+14aJC/LhqVqCvHp+j09CgWywJeirICwJKKK2u1bEuh3tlcoI1HbdoW4GfT2UNiNWtMkmaMiFefIP4aA7wdf8oBWEZFdZ0++KZIb28u0Jq9pW0LZW02acqAaF06JkkzRyYoss/xb3YKwPtQVgCY6nClW8u3HdL73xTqqz2lamj69nZl49IidemYJF08KlFxEWzaBvgqygqAXldQUaMPvinSB1uLtG5/mY6+nWpGYoRmjUnSJaMTlRrVx7yQACyDsgKgV+wvqdL7LQVlc15Fu9fGpDh04chEXTgyQf25kgfAMSgrAHqEYRj6Jt+lj7cf0odbi7SjqLLtNZtNmtgvSheOTNAFIxOUHBliYlIAVkdZAdBtausbtXpPiT7eXqxPth/SIZe77bUAP5umDIzWhSMTNGN4gmLD2fIeQNdQVgB8L8WVtVqxvVgfby/WlzklqqlvbHutT5C/zhoco/My4nX+8Hiu4gFwSigrAE6KYRjaUVSpj7cd0sc7ijusP0l0BOu8jHhNz4jT5AHRCg70NycoAK9BWQHwnVy19fpyd4lW7TqsVbsOq9BZ2+71MSkOTW8pKMMTI7hhIIBuRVkB0EFTk6Ftha7mcrLzsDbklqvxqP1P7AF+OmtwjKZnxOvcYXGKZw8UAD2IsgJAklRWVafPdzePnHy2q0QlR9ztXh8QG6pzhsRq2tA4TeofxfQOgF5DWQF8VH1jk7LyKvRFy/TO5oMV7TZn6xPkr6kDYzRtaKzOGRLLBm0ATENZAXyEYRjaeahSX+wu0eo9pfp6b6mq6hrbnTMsIVznDInVOUNjNaFflIIC/ExKCwDfoqwAXiy/okZf7i7RFznNBeXYqZ2+fQI1dWCMzh4So3OGxCnBwdoTANZDWQG8SEV1nb7aU6ovckr0ZU6J9pdWt3s9ONBPp/eP1pmDojV1YIyGJ0bIz48rdwBYG2UF8GDOmnqt31+mNXtLtWZvmb4pcLZbd+LvZ9PoFIfOHBSjMwbFaGxapOwBLIwF4FkoK4AHqaiu09p9Zfp6X5m+3leqrQWuduVEkgbHhemMlnIyaUCUIoIDzQkLAN2EsgJYWHlVXVsxWbO3TDuKOpaT/jGhmtQ/SpMGRGnqwBj2PAHgdSgrgIWUHnG3jZys2Vva7k7FrQbEhmrygGhN6h+lyQOiKScAvB5lBTCJYRjKLavW+v3lWn+gTOv2lyun+EiH8wbFhWnygChN6h+tSQOiFBdOOQHgWygrQC9paGzStkKX1u0v14aWcnK40t3hvCHxYS0jJ9E6vX+UYsPtJqQFAOugrAA95Ii7QZtyy7Vuf7nW7y9TVl6Fqo/ZhC3Q36ZRyQ5NTI/S+H59Nb5fX0WHUU4A4GiUFaCbFDlrtf5AmdbvL9e6/WXaXuhS0zGLYSOCAzS+X19NSI/SxPQojU5xcI8dAPgOlBXgFLgbGrWtwKVNuRXamFuuTbkVyq+o6XBeSt+QtlGTielRGhwXxiZsAHCSKCvAdzAMQwXOWm1qKSUbc8u1Nd+lusamduf52aSMxAhNTI/ShPS+mtAviu3rAaAbUFaAY9TWNyo736mNB5rLyaa8ch1ydVwIGxUapLGpkRqbFqlxaX01OjVSYXb+SAFAd+NvVvi01suHN+VWaFNuuTbmVmh7oUsNxyw28fezKSMxXOPS+mpsWqTGpvZVv+g+stmY0gGAnkZZgU8pq6rT5oMV2pLn1JaDFcrKq1BpVV2H82LD7RqXFqmxaX01Lq2vRiU7FBLEQlgAMANlBV6ryt2gb/Kd2nLQqc0HK7T5YIXyyjougg30t2lEkuPbUZO0SCVHhjBqAgAWQVmBV6hvbNLOokpl5VVoy8EKbc5zandxZYdLhyVpQEyoRqc4NDolUmNSIzUiKYLLhwHAwigr8DhNTYb2lVZpc16Fthx0KiuvQtsKXapraOpwbkJEsEanODQmNVJjUiI1KsUhRwh3IQYAT0JZgaUZhqFCZ23bVM6Wg80FpbK2ocO5EcEBbaWktaBwkz8A8HyUFViGYRjKr6jRN/lOZec7lZ3v0tZ8Z6cLYIMD/TQyqXUqx6ExKZFcnQMAXoqyAlMYhqGD5TUtpcSpb1oe5dX1Hc4N8LNpcHy4TkttKScpkRoSH6YAfz8TkgMAehtlBT2udS+T9sXEJWdNx2IS6G/TkPhwjUp2aGTLY1hCOAtgAcCHUVbQrZqaDO0vrdI3Ba7m6ZyDTn1T0PkakyB/Pw1NCG8pJREalezQ0IRw2QMoJgCAb1FWcMqamgztLanS1oLmUpKd79S2Apcq3Z0UkwA/ZbQVE4dGJTs0JD5cQQFM5QAAToyygi5xNzRqV9ERbSt0amuBS9sKXNpe6FJVXWOHc4MC/JSRGKFRLaMlI1uKSSBrTAAAp4Cygg6cNfXaXujS1gKXthY0j5bkFB/pcL8cqfmqnOZi8u2IyaC4MIoJAKDbUFZ8mGEYKnLValvBUcWk0NXplvSS5AgJ1IikCI1IitDwpAiNSHJoQEwoV+UAAHoUZcVHNDYZ2teyvmRbgUvbWkZOyjrZw0SSkiNDWgpJhIYnRmhEskNJjmD2MQEA9DrKiheqrW/UzqLKdqMlOworVVPfcX2Jv59NA2NDNSLJ0VxKWkZNIvsEmZAcAICOKCserqK6rsM0zp7DVWrsZH1JSKC/hiWGt4yWODQiKUJD2cMEAGBxlBUP0diyf8mOwkptL3S1PQqctZ2eHxUa1DZK0jxi4lD/mFD5+zGNAwDwLJQVC6qsrdeOom9LybbCSu0q6nwaR5JSo0I0ItHRtsZkRJJD8RF21pcAALwCZcVETU2G8sqr2wpJazk5WN751Tj2AD8NSwhXRmLEt/9MjJAjJLCXkwMA0HsoK72kyt2gHUWV2lHUOoVTqR3H2VRNkhIigpWR2FxIWh9M4wAAfBFlpZsZhqH8ihptP2ZtyYGyahkd17wqyN9Pg+PDjiol4cpIiFDfUK7GAQBA6uGy8thjj2nZsmXKyspSUFCQKioqOpyTm5uru+66SytWrFBISIiuu+46/e53v1NQkPU/rFsvEf62lFRqe5Gr05v2SVJsuL2tkAxPjNCwhAgNiA1lt1cAAE6gR8tKXV2drr76ak2ZMkUvvPBCh9cbGxt18cUXKzY2Vl988YVKS0s1b948GYahp556qiejnZTWnV7bCklLOdlXUqVOrhBWgJ9Ng+LCmgvJUVM5MWH23g8PAICH69GysnDhQknSiy++2OnrH330kbZt26a8vDwlJSVJkp588knddNNNeuyxxxQREdGT8U5ow4EyLdtS1FxMilyqqK7v9Lyo0KC2qZvWUjIoLoy7CQMA0E1MXbPy1VdfaeTIkW1FRZIuuOACud1ubdiwQZmZmR2+xu12y+12tz13uVw9km1rgUt/+3Jf23N/P5sGxIS2W1syPDFCseFcIgwAQE8ytawUFRUpPj6+3bG+ffsqKChIRUVFnX7NokWL2kZsetLE9CjdfEZ6czFJiNDg+DB2egUAwAQnPVfxyCOPyGaznfCxfv36Ln+/zkYlDMM47mjFAw88IKfT2fbIy8s72V9Cl2QkRujhS0fomgmpGpXioKgAAGCSkx5ZufvuuzV37twTnpOent6l75WQkKCvv/663bHy8nLV19d3GHFpZbfbZbezUBUAAF9x0mUlJiZGMTEx3fLDp0yZoscee0yFhYVKTEyU1Lzo1m63a/z48d3yMwAAgGfr0TUrubm5KisrU25urhobG5WVlSVJGjRokMLCwjRjxgwNHz5cN9xwg5544gmVlZVpwYIFuu2220y9EggAAFhHj5aVX/ziF3rppZfano8dO1aStHLlSk2bNk3+/v5atmyZ7rzzTp1xxhntNoUDAACQJJthdLYJvOdwuVxyOBxyOp2MxgAA4CFO5vObncsAAIClUVYAAIClUVYAAIClUVYAAIClUVYAAIClUVYAAIClUVYAAIClUVYAAICl9egOtr2hdU87l8tlchIAANBVrZ/bXdmb1uPLSmVlpSQpNTXV5CQAAOBkVVZWyuFwnPAcj99uv6mpSQUFBQoPD5fNZuvW7+1yuZSamqq8vDy28v8OvFddx3vVdbxXXcd71XW8Vyenp94vwzBUWVmppKQk+fmdeFWKx4+s+Pn5KSUlpUd/RkREBL+hu4j3qut4r7qO96rreK+6jvfq5PTE+/VdIyqtWGALAAAsjbICAAAsjbJyAna7XQ8//LDsdrvZUSyP96rreK+6jveq63ivuo736uRY4f3y+AW2AADAuzGyAgAALI2yAgAALI2yAgAALI2yAgAALI2yAgAALI2y0kWzZs1SWlqagoODlZiYqBtuuEEFBQVmx7Kc/fv365ZbblH//v0VEhKigQMH6uGHH1ZdXZ3Z0Szpscce09SpU9WnTx9FRkaaHcdy/vKXv6h///4KDg7W+PHj9fnnn5sdyXI+++wzXXrppUpKSpLNZtPSpUvNjmRZixYt0sSJExUeHq64uDjNnj1bO3fuNDuWJT3zzDMaPXp02661U6ZM0fvvv29aHspKF2VmZur111/Xzp079cYbb2jPnj266qqrzI5lOTt27FBTU5Oee+45bd26VX/4wx/07LPP6sEHHzQ7miXV1dXp6quv1h133GF2FMt57bXXdO+99+qhhx7Spk2bdNZZZ2nmzJnKzc01O5qlVFVVacyYMXr66afNjmJ5q1at0l133aU1a9Zo+fLlamho0IwZM1RVVWV2NMtJSUnRr3/9a61fv17r16/Xueeeq8suu0xbt241JQ/7rJyit99+W7Nnz5bb7VZgYKDZcSztiSee0DPPPKO9e/eaHcWyXnzxRd17772qqKgwO4plTJo0SePGjdMzzzzTdiwjI0OzZ8/WokWLTExmXTabTW+++aZmz55tdhSPcPjwYcXFxWnVqlU6++yzzY5jeVFRUXriiSd0yy239PrPZmTlFJSVlemVV17R1KlTKSpd4HQ6FRUVZXYMeJC6ujpt2LBBM2bMaHd8xowZWr16tUmp4G2cTqck8ffTd2hsbNSSJUtUVVWlKVOmmJKBsnISfvaznyk0NFTR0dHKzc3VW2+9ZXYky9uzZ4+eeuop3X777WZHgQcpKSlRY2Oj4uPj2x2Pj49XUVGRSangTQzD0Pz583XmmWdq5MiRZsexpOzsbIWFhclut+v222/Xm2++qeHDh5uSxafLyiOPPCKbzXbCx/r169vO/+lPf6pNmzbpo48+kr+/v2688Ub5yizayb5XklRQUKALL7xQV199tW699VaTkve+U3mv0DmbzdbuuWEYHY4Bp+Luu+/Wli1b9M9//tPsKJY1dOhQZWVlac2aNbrjjjs0b948bdu2zZQsAab8VIu4++67NXfu3BOek56e3vbvMTExiomJ0ZAhQ5SRkaHU1FStWbPGtGGx3nSy71VBQYEyMzM1ZcoUPf/88z2czlpO9r1CRzExMfL39+8wilJcXNxhtAU4Wffcc4/efvttffbZZ0pJSTE7jmUFBQVp0KBBkqQJEyZo3bp1+uMf/6jnnnuu17P4dFlpLR+nonVExe12d2ckyzqZ9yo/P1+ZmZkaP368Fi9eLD8/3xrA+z6/r9AsKChI48eP1/Lly3X55Ze3HV++fLkuu+wyE5PBkxmGoXvuuUdvvvmmPv30U/Xv39/sSB7FMAzTPvN8uqx01dq1a7V27VqdeeaZ6tu3r/bu3atf/OIXGjhwoE+MqpyMgoICTZs2TWlpafrd736nw4cPt72WkJBgYjJrys3NVVlZmXJzc9XY2KisrCxJ0qBBgxQWFmZuOJPNnz9fN9xwgyZMmNA2Qpebm8v6p2McOXJEOTk5bc/37dunrKwsRUVFKS0tzcRk1nPXXXfp1Vdf1VtvvaXw8PC2kTuHw6GQkBCT01nLgw8+qJkzZyo1NVWVlZVasmSJPv30U33wwQfmBDLwnbZs2WJkZmYaUVFRht1uN9LT043bb7/dOHjwoNnRLGfx4sWGpE4f6GjevHmdvlcrV640O5ol/PnPfzb69etnBAUFGePGjTNWrVpldiTLWblyZae/h+bNm2d2NMs53t9NixcvNjua5fzgBz9o+7MXGxtrTJ8+3fjoo49My8M+KwAAwNJ8azEBAADwOJQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaZQVAABgaf8f6fTO3OPUFZAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_pr4_b(x):\n",
    "    return np.exp(x)+x-7.\n",
    "\n",
    "x = np.linspace(-3,3,1000)\n",
    "plt.plot(x,f_pr4_b(x))\n",
    "plt.title('Problem 3')\n",
    "plt.axhline(color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the intial guess be $1$ for example. Note for\n",
    "\\begin{equation*}\n",
    "g(x) = 7-e^x\n",
    "\\end{equation*}\n",
    "$|g'(1.8)| > 1$. So another $g$ needs to be used.\n",
    "\n",
    "The following $g$ function works:\n",
    "\\begin{equation*}\n",
    "g(x) = \\log{(7-x)}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approx solution g(x) with |x-g(x)|< 1e-08 found in 11 iterations\n",
      "1.6728216974043735\n",
      "The original function f value evaluated at  1.6728216974043735  is:  -7.747838814964325e-09\n"
     ]
    }
   ],
   "source": [
    "def g_pr4_b(x):\n",
    "    return np.log(7.-x)\n",
    "\n",
    "x_0 = 1.\n",
    "tol = 1e-8\n",
    "sol_b, nstep = fpi_tol(g_pr4_b, x_0, tol)\n",
    "print('The approx solution g(x) with |x-g(x)|<',tol,'found in',nstep,'iterations')\n",
    "print(sol_b)\n",
    "\n",
    "# Check if the solution is correct:\n",
    "print('The original function f value evaluated at ', sol_b, ' is: ', f_pr4_b(sol_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "(2.4-1) Use the Python codes for the secant and Newton's methods to find solutions\n",
    "for the equation $\\sin x-e^{-x}=0$ on $0\\leq x\\leq1$. Set tolerance\n",
    "to $10^{-4}$, and take $p_{0}=0$ in Newton, and $p_{0}=0,p_{1}=1$\n",
    "in secant method. Do a visual inspection of the estimates and comment\n",
    "on the convergence rates of the methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def newton2(f, fprime, pin, eps, N):\n",
    "    n = 1\n",
    "    p = 0. # to ensure the value of p carries out of the while loop\n",
    "    while n <= N:\n",
    "        p = pin - f(pin)/fprime(pin)\n",
    "        print('p is ', p, ' and the iteration is ', n)\n",
    "        if f(p) == 0:\n",
    "            return\n",
    "        pin = p\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def secant2(f, pzero, pone, eps, N):\n",
    "    n = 1\n",
    "    p = 0. # to ensure the value of p carries out of the while loop\n",
    "    while n <= N:\n",
    "        p = pone - f(pone)*(pone-pzero) / (f(pone)-f(pzero))\n",
    "        print('p is ', p, ' and the iteration is ', n)\n",
    "        if f(p) == 0:\n",
    "            return\n",
    "        pzero = pone\n",
    "        pone = p\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is  0.5  and the iteration is  1\n",
      "p is  0.5856438169664325  and the iteration is  2\n",
      "p is  0.5885294126263548  and the iteration is  3\n",
      "p is  0.5885327439774188  and the iteration is  4\n",
      "p is  0.5885327439818611  and the iteration is  5\n"
     ]
    }
   ],
   "source": [
    "newton2(lambda x: np.sin(x)-np.exp(-x), lambda x: np.cos(x)+np.exp(-x), \n",
    "       0, 1e-4, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is  0.6786141005751505  and the iteration is  1\n",
      "p is  0.5690622514011432  and the iteration is  2\n",
      "p is  0.5892596135984055  and the iteration is  3\n",
      "p is  0.5885383580178513  and the iteration is  4\n",
      "p is  0.5885327423478889  and the iteration is  5\n",
      "p is  0.5885327439818647  and the iteration is  6\n",
      "p is  0.5885327439818612  and the iteration is  7\n",
      "p is  0.5885327439818611  and the iteration is  8\n"
     ]
    }
   ],
   "source": [
    "secant2(lambda x: np.sin(x)-np.exp(-x), 0, 1, 1e-4, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method converges much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Write a general $LU$ factorization code and use it to solve\n",
    "$$\n",
    "\\left[\\begin{array}{lll}{4} & {2} & {0} \\\\ {4} & {4} & {2} \\\\ {2} & {2} & {3}\\end{array}\\right]\\left[\\begin{array}{l}{x_{1}} \\\\ {x_{2}} \\\\ {x_{3}}\\end{array}\\right]=\\left[\\begin{array}{l}{2} \\\\ {4} \\\\ {6}\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LU(A):\n",
    "    \"\"\"\n",
    "    LU factorization without pivoting. \n",
    "    The coefficient matrix A is modified in place.\n",
    "    The lower triangular part of A represents the L matrix, the upper triangular part \n",
    "    (including the diagonal) represents U\n",
    "    A: the coefficient matrix of size n x n   \n",
    "    \"\"\"\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        print('The given coefficient matrix is not square')\n",
    "        stop   \n",
    "     \n",
    "    # We hard code the epsilon here. It can be an input parameter.\n",
    "    eps = 1e-5 \n",
    "    n = A.shape[0]\n",
    "\n",
    "    for j in range(n-1):\n",
    "        if np.abs(A[j,j]) < eps:\n",
    "            print('Zero pivot encountered!')\n",
    "            stop\n",
    "        for i in range(j+1, n):\n",
    "            # The multiplier\n",
    "            mp = A[i,j]/A[j,j]\n",
    "            A[i,j] = mp\n",
    "            for k in range(j+1,n):\n",
    "                A[i,k] = A[i,k] - mp*A[j,k]\n",
    "    \n",
    "    # No need to return. Both A and b are changed in place\n",
    "    \n",
    "def forward_sub(A, b, A_from_LU):\n",
    "    \"\"\"\n",
    "    Forward substitution\n",
    "    The right hand side b is changed in place to store the solution\n",
    "    A: the coefficient matrix of size n x n\n",
    "    b: the right hand side of size n\n",
    "    A_from_LU: True, if the matrix A is from LU factorization (diagonals are 1).\n",
    "               False, if A is just a regular coefficient matrix\n",
    "    \"\"\"\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        print('The given coefficient matrix is not square')\n",
    "        stop\n",
    "    \n",
    "    if A.shape[0] != b.size:\n",
    "        print('The shape of the coefficient matrix does not match the size of the RHS')\n",
    "        stop\n",
    "     \n",
    "    n = A.shape[0]\n",
    "    \n",
    "    if A_from_LU:\n",
    "        for j in range(0,n):       \n",
    "            b[j+1:] = b[j+1:] - A[j+1:,j]*b[j]\n",
    "    else:\n",
    "        for j in range(0,n):  \n",
    "            b[j,j] = b[j,j]/A[j,j]\n",
    "            b[j+1:] = b[j+1:] - A[j+1:,j]*b[j]\n",
    "\n",
    "def back_sub(A, b):\n",
    "    \"\"\"\n",
    "    Backward substitution\n",
    "    The right hand side b is changed in place to store the solution\n",
    "    A: the coefficient matrix of size n x n\n",
    "    b: the right hand side of size n\n",
    "    \"\"\"\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        print('The given coefficient matrix is not square')\n",
    "        stop\n",
    "    \n",
    "    if A.shape[0] != b.size:\n",
    "        print('The shape of the coefficient matrix does not match the size of the RHS')\n",
    "        stop\n",
    "     \n",
    "    n = A.shape[0]\n",
    "    \n",
    "    for i in range(n-1, -1, -1):\n",
    "        for j in range(i+1, n):\n",
    "            b[i] = b[i] - A[i,j]*b[j]\n",
    "        b[i] = b[i]/A[i,i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix A after LU decomposition is \n",
      "[[4.  2.  0. ]\n",
      " [1.  2.  2. ]\n",
      " [0.5 0.5 2. ]]\n",
      "After forward substition, the vector b is\n",
      "[2. 2. 4.]\n",
      "After backward substition, the vector b is\n",
      "[ 1. -1.  2.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[4.,2.,0.], [4.,4.,2.], [2.,2.,3.]])\n",
    "b = np.array([2.,4.,6.])\n",
    "A_copy = A.copy()  # optional\n",
    "b_copy = b.copy()\n",
    "# Perform LU factorization\n",
    "LU(A)\n",
    "print('The matrix A after LU decomposition is ')\n",
    "print(A)\n",
    "# Perform forward substitution\n",
    "forward_sub(A,b,True)\n",
    "print('After forward substition, the vector b is')\n",
    "print(b)\n",
    "# Perform back substitution\n",
    "back_sub(A,b)\n",
    "print('After backward substition, the vector b is')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# test - optional\n",
    "err = np.dot(A_copy,b) - b_copy\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Let $A$ be the $n\\times n$ matrix with entries $A_{ij}=|i-j|+1$. Define $x=[1,\\dots,1]^T$ and $b=Ax$. For $n=100,200,300,400$ and $500$, use the Python function numpy.linalg.solve to compute $x_c$, the double precision computed solution. For each solution, calculate the infinity norm of the forward error, find the error magnification factor, and compare with the corresponding condition numbers. Use the default norm provided by np.linalg.norm, which, for vectors, is the Euclidean norm $\\|x\\|=\\left(\\sum_{k=1}^n |x_k|^2\\right)^{1/2}$.\n",
    "\n",
    "**MATH 5660 only**: Compute the maximum error magnification factor in the vector norm provided by np.linalg.norm. Hint: Look up the description of np.linalg.norm and matrix norms to find which matrix norm of $A$ equals $\\max_{x\\ne 0}\\frac{\\|Ax\\|}{\\|x\\|}$ for the same Euclidean vector norm as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Compute $x_c$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n =  100  the forward error in infinity norm is  2.531752585355207e-12\n",
      "For n =  100  the error magnification factor in infinity norm is  3514.4104003906245\n",
      "For n =  100  the condition number in infinity norm is  10100.000000006721 from numpy 10100.000000006721 difference 0.0\n",
      "For n =  100  the error manification factor is 0.3479614257810184 of the condition number, in infinity norm\n",
      "For n =  100  the condition number in infinity norm from numpy is  10100.000000006721\n",
      "For n =  100  the forward error in default norm is  9.128292226590236e-12\n",
      "For n =  100  the error magnification factor in default norm is  2235.521698041085\n",
      "For n =  100  the condition number in default norm is  7138.87731965427 from numpy 7138.8773196543525 difference -8.276401786133647e-11\n",
      "For n =  100  the error manification factor is 0.313147515770638 of the condition number, in default norm\n",
      "For n =  100  the condition number in default norm from numpy is  7138.8773196543525\n",
      "For n =  200  the forward error in infinity norm is  2.126698817050965e-11\n",
      "For n =  200  the error magnification factor in infinity norm is  29375.271606445312\n",
      "For n =  200  the condition number in infinity norm is  40200.00000017773 from numpy 40200.00000017773 difference 0.0\n",
      "For n =  200  the error manification factor is 0.7307281494108319 of the condition number, in infinity norm\n",
      "For n =  200  the condition number in infinity norm from numpy is  40200.00000017773\n",
      "For n =  200  the forward error in default norm is  7.854492324760359e-11\n",
      "For n =  200  the error magnification factor in default norm is  14084.250403030375\n",
      "For n =  200  the condition number in default norm is  28176.505492872482 from numpy 28176.505492873108 difference -6.257323548197746e-10\n",
      "For n =  200  the error manification factor is 0.49985795458535914 of the condition number, in default norm\n",
      "For n =  200  the condition number in default norm from numpy is  28176.505492873108\n",
      "For n =  300  the forward error in infinity norm is  7.525047251988326e-11\n",
      "For n =  300  the error magnification factor in infinity norm is  58369.61631774902\n",
      "For n =  300  the condition number in infinity norm is  90300.00000177609 from numpy 90300.00000177609 difference 0.0\n",
      "For n =  300  the error manification factor is 0.6463966369501768 of the condition number, in infinity norm\n",
      "For n =  300  the condition number in infinity norm from numpy is  90300.00000177609\n",
      "For n =  300  the forward error in default norm is  2.8206039202387897e-10\n",
      "For n =  300  the error magnification factor in default norm is  38843.14261559842\n",
      "For n =  300  the condition number in default norm is  63110.44844909452 from numpy 63110.44844909819 difference -3.67435859516263e-09\n",
      "For n =  300  the error manification factor is 0.6154787926587095 of the condition number, in default norm\n",
      "For n =  300  the condition number in default norm from numpy is  63110.44844909819\n",
      "For n =  400  the forward error in infinity norm is  1.444757646851258e-10\n",
      "For n =  400  the error magnification factor in infinity norm is  79624.9575805664\n",
      "For n =  400  the condition number in infinity norm is  160400.0000059148 from numpy 160400.0000059148 difference 0.0\n",
      "For n =  400  the error manification factor is 0.49641494749146015 of the condition number, in infinity norm\n",
      "For n =  400  the condition number in infinity norm from numpy is  160400.0000059148\n",
      "For n =  400  the forward error in default norm is  5.803777482065902e-10\n",
      "For n =  400  the error magnification factor in default norm is  55052.13284952229\n",
      "For n =  400  the condition number in default norm is  111940.71815079954 from numpy 111940.71815087079 difference -7.12461769580841e-08\n",
      "For n =  400  the error manification factor is 0.49179720979956104 of the condition number, in default norm\n",
      "For n =  400  the condition number in default norm from numpy is  111940.71815087079\n",
      "For n =  500  the forward error in infinity norm is  2.0997448224591153e-10\n",
      "For n =  500  the error magnification factor in infinity norm is  129091.02875845773\n",
      "For n =  500  the condition number in infinity norm is  250500.00001188088 from numpy 250500.00001188088 difference 0.0\n",
      "For n =  500  the error manification factor is 0.5153334481131142 of the condition number, in infinity norm\n",
      "For n =  500  the condition number in infinity norm from numpy is  250500.00001188088\n",
      "For n =  500  the forward error in default norm is  1.2032577663507025e-09\n",
      "For n =  500  the error magnification factor in default norm is  93496.12077568228\n",
      "For n =  500  the condition number in default norm is  174667.31700416375 from numpy 174667.31700418063 difference -1.6880221664905548e-08\n",
      "For n =  500  the error manification factor is 0.5352811411962863 of the condition number, in default norm\n",
      "For n =  500  the condition number in default norm from numpy is  174667.31700418063\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    n = (k+1)*100\n",
    "    A = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            A[i,j] = np.abs((i+1)-(j+1))+1\n",
    "    # True solution:\n",
    "    sol_true = np.ones(n,)\n",
    "    b = np.dot(A, sol_true)    \n",
    "    # numerical solution\n",
    "    sol = np.linalg.solve(A, b)\n",
    "    \n",
    "    # in infinity norm\n",
    "    # forward error:\n",
    "    fwd_err = np.linalg.norm(sol-sol_true, np.inf)\n",
    "    # relative forward error:\n",
    "    rel_fwd_err = fwd_err / np.linalg.norm(sol_true, np.inf)\n",
    "    # backward error:\n",
    "    back_err = np.linalg.norm(b-np.dot(A,sol), np.inf)\n",
    "    # relative backward error:\n",
    "    rel_back_err = back_err / np.linalg.norm(b, np.inf)\n",
    "    # error magnification factor:\n",
    "    err_mag_factor = rel_fwd_err / rel_back_err\n",
    "    # condition number\n",
    "    norm_A = np.linalg.norm(A, np.inf)\n",
    "    norm_invA = np.linalg.norm(np.linalg.inv(A), np.inf)\n",
    "    cond_A = norm_A * norm_invA\n",
    "\n",
    "    \n",
    "    print('For n = ', n, ' the forward error in infinity norm is ', fwd_err)\n",
    "    print('For n = ', n, ' the error magnification factor in infinity norm is ', err_mag_factor)\n",
    "    print('For n = ', n, ' the condition number in infinity norm is ', cond_A,'from numpy',np.linalg.cond(A,np.inf),'difference',cond_A-np.linalg.cond(A,np.inf))\n",
    "    print('For n = ', n, ' the error manification factor is', err_mag_factor/cond_A,'of the condition number, in infinity norm')\n",
    "    print('For n = ', n, ' the condition number in infinity norm from numpy is ', np.linalg.cond(A, np.inf)) # optional\n",
    "    \n",
    "    \n",
    "    # in default norm\n",
    "    # forward error:\n",
    "    fwd_err = np.linalg.norm(sol-sol_true)\n",
    "    # relative forward error:\n",
    "    rel_fwd_err = fwd_err / np.linalg.norm(sol_true)\n",
    "    # backward error:\n",
    "    back_err = np.linalg.norm(b-np.dot(A,sol))\n",
    "    # relative backward error:\n",
    "    rel_back_err = back_err / np.linalg.norm(b)\n",
    "    # error magnification factor:\n",
    "    err_mag_factor = rel_fwd_err / rel_back_err\n",
    "    # condition number\n",
    "    norm_A = np.linalg.norm(A,ord=2)\n",
    "    norm_invA = np.linalg.norm(np.linalg.inv(A),ord=2)\n",
    "    cond_A = norm_A * norm_invA\n",
    "    \n",
    "    print('For n = ', n, ' the forward error in default norm is ', fwd_err)\n",
    "    print('For n = ', n, ' the error magnification factor in default norm is ', err_mag_factor)\n",
    "    print('For n = ', n, ' the condition number in default norm is ',cond_A,'from numpy',np.linalg.cond(A,p=2),'difference',cond_A-np.linalg.cond(A,p=2))\n",
    "    print('For n = ', n, ' the error manification factor is', err_mag_factor/cond_A,'of the condition number, in default norm')\n",
    "    print('For n = ', n, ' the condition number in default norm from numpy is ', np.linalg.cond(A))   # optional\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison: in all cases, the error magnification error is a substantial fraction of the condition number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution MATH 5660 additional part only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For $\\|x\\|$ the infinity norm, $\\max_{x\\ne 0}\\frac{\\|Ax\\|}{\\|x\\|}$ is np.linalg.norm(A,np.inf)\n",
    "\n",
    "For $\\|x\\|$ the default norm (the 2-norm), $\\max_{x\\ne 0}\\frac{\\|Ax\\|}{\\|x\\|}$ is np.linalg.norm(A,ord=2)\n",
    "\n",
    "The maximum error magnification factor is $\\max_{\\delta b\\ne 0}\\frac{\\|A^{-1}\\delta b\\|}{\\|\\delta b\\|}  \\max_{x\\ne 0} \\frac{\\|Ax\\|}{\\|x\\|}$ (textbook, ch.3.1 Condition Number section),\n",
    "which is $\\|A\\| \\|A^{-1}\\|$ already computed in the previous part: np.linalg.norm(A,ord=2)*np.linalg.norm(np.linalg.inv(A),ord=2) for the 2-norm, and np.linalg.norm(A,np.inf)*np.linalg.norm(np.linalg.inv(A),np.inf) for the infinity norm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grading notes\n",
    "Use of either the default norm or the infinity norm is accepted, but it should be consistent.\n",
    "Computing the condition number either way, as $\\|A\\|\\,\\|A^{-1}\\|$, or by np.linalg.cond, is accepted, if correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PALU(A):\n",
    "    \"\"\"\n",
    "    PA=LU factorization with partial pivoting. \n",
    "    The coefficient matrix A is modified in place.\n",
    "    The lower triangular part of A represents the L matrix, the upper triangular part \n",
    "    (including the diagonal) represents U\n",
    "    A: the coefficient matrix of size n x n\n",
    "    output:\n",
    "    Permutation matrix $P$ is returned, along with $A$ that is changed in place\n",
    "    \"\"\"\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        print('The given coefficient matrix is not square')\n",
    "        stop   \n",
    "     \n",
    "    # We hard code the epsilon here. It can be an input parameter.\n",
    "    n = A.shape[0]\n",
    "    P = np.eye(n)\n",
    "\n",
    "    for j in range(n-1):\n",
    "        print(A)\n",
    "        # find p\n",
    "        p = np.argmax(np.abs(A[j:,j]))        \n",
    "        if p+j != j:\n",
    "            # change rows p and j of A. Update P:\n",
    "            A[[p+j, j]] = A[[j, p+j]]\n",
    "            P[[p+j, j]] = P[[j, p+j]]   \n",
    "        for i in range(j+1, n):\n",
    "            # The multiplier\n",
    "            mp = A[i,j]/A[j,j]\n",
    "            A[i,j] = mp\n",
    "            for k in range(j+1,n):\n",
    "                A[i,k] = A[i,k] - mp*A[j,k]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform PA=LU factorization of A = : \n",
      "Before PA=LU factorization, A = \n",
      "[[-9.  1. 17.]\n",
      " [ 3.  2. -1.]\n",
      " [ 6.  8.  1.]]\n",
      "[[-9.  1. 17.]\n",
      " [ 3.  2. -1.]\n",
      " [ 6.  8.  1.]]\n",
      "[[-9.          1.         17.        ]\n",
      " [-0.33333333  2.33333333  4.66666667]\n",
      " [-0.66666667  8.66666667 12.33333333]]\n",
      "The PA=LU factorization result is \n",
      "After PA=LU factorization, A = \n",
      "[[-9.          1.         17.        ]\n",
      " [-0.66666667  8.66666667 12.33333333]\n",
      " [-0.33333333  0.26923077  1.34615385]]\n",
      "The permutation matrix P = \n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[-9., 1, 17], [3, 2, -1], [6, 8, 1]])\n",
    "print('Perform PA=LU factorization of A = : ')\n",
    "print('Before PA=LU factorization, A = ')\n",
    "print(A)\n",
    "A_copy = A.copy()  # optional\n",
    "\n",
    "P = PALU(A)\n",
    "print('The PA=LU factorization result is ')\n",
    "print('After PA=LU factorization, A = ')\n",
    "print(A)\n",
    "print('The permutation matrix P = ')\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L*U - P*A_copy = \n",
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00 -8.8817842e-16  0.0000000e+00]\n",
      " [ 0.0000000e+00  4.4408921e-16  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# test - optional\n",
    "# Extracting L and U from the modified A\n",
    "U = np.triu(A)\n",
    "L = A - U + np.eye(A.shape[0])\n",
    "# Verifying that L*U = P*A_copy\n",
    "result = np.dot(L, U) - np.dot(P, A_copy)\n",
    "\n",
    "print(\"L*U - P*A_copy = \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
